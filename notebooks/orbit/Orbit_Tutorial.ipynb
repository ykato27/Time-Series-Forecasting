{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bc0dbd",
   "metadata": {},
   "source": [
    "# An Example of Forecasting / Nowcasting with DLT\n",
    "\n",
    "In this session, we will explore:\n",
    "\n",
    "- Orbit Installation\n",
    "- A forecasting task on iclaims dataset\n",
    "- A simple DLT model\n",
    "- DLT model with regression settings\n",
    "- Disgnoses\n",
    "\n",
    "For more examples you can find on [Github](https://github.com/uber/Orbit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3804c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import orbit\n",
    "from orbit.utils.dataset import load_iclaims\n",
    "from orbit.models.dlt import DLTFull, DLTMAP\n",
    "from orbit.diagnostics.plot import (\n",
    "    plot_predicted_data,\n",
    "    plot_predicted_components,\n",
    "    plot_posterior_params,\n",
    ")\n",
    "from orbit.constants.palette import QualitativePalette\n",
    "from orbit.diagnostics.metrics import smape\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pylab import rcParams\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 14, 8\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(x, y):\n",
    "    return np.mean(np.abs(x - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828891a2",
   "metadata": {},
   "source": [
    "# US Weekly Initial Claims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdab028",
   "metadata": {},
   "source": [
    "The *iclaims* data contains the weekly initial claims for US unemployment benefits against a few related google trend queries (unemploy, filling and job) \n",
    "from Jan 2010 - June 2018. This dataset was used in the original Bayesian Structural Time-Series paper [Scott and Varan (2013)](https://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf) as well.\n",
    "\n",
    "Number of claims are obtained from [Federal Reserve Bank of St. Louis](https://fred.stlouisfed.org/series/ICNSA) while regressors such as google queries are obtained through [Google Trends API](https://trends.google.com/trends/?geo=US).\n",
    "\n",
    "In order to use this data to nowcast the US unemployment claims considering the impact of COVID-19, we extended the dataset to Jan 2021 and added the [S&P 500 (^GSPC)](https://finance.yahoo.com/quote/%5EGSPC/history?period1=1264032000&period2=1611187200&interval=1wk&filter=history&frequency=1wk&includeAdjustedClose=true) and [VIX](https://finance.yahoo.com/quote/%5EVIX/history?p=%5EVIX) Index historical data for the same period.\n",
    "\n",
    "**Note:** The data is standardized and log-transformed for the model fitting purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7260580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = load_iclaims(end_date=\"2021-01-03\")\n",
    "df = df[[\"week\", \"claims\", \"trend.unemploy\", \"trend.job\", \"sp500\", \"vix\"]]\n",
    "date_col = \"week\"\n",
    "response_col = \"claims\"\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0a114",
   "metadata": {},
   "source": [
    "To introduce forecastability, we use one week lag of data for the regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"trend.unemploy\", \"trend.job\", \"sp500\", \"vix\"]] = df[\n",
    "    [\"trend.unemploy\", \"trend.job\", \"sp500\", \"vix\"]\n",
    "].shift(1)\n",
    "df = df[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34966988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e652d",
   "metadata": {},
   "source": [
    "We can see from the charts below, there are seasonlity, trend, and as well as a huge changpoint due the impact of COVID-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(20, 8))\n",
    "axs[0, 0].plot(df[\"week\"], df[\"claims\"])\n",
    "axs[0, 0].set_title(\"Unemployment Claims\")\n",
    "axs[0, 1].plot(df[\"week\"], df[\"trend.unemploy\"], \"tab:orange\")\n",
    "axs[0, 1].set_title(\"Google trend - unemploy\")\n",
    "axs[1, 0].plot(df[\"week\"], df[\"vix\"], \"tab:green\")\n",
    "axs[1, 0].set_title(\"VIX\")\n",
    "axs[1, 1].plot(df[\"week\"], df[\"sp500\"], \"tab:red\")\n",
    "axs[1, 1].set_title(\"S&P500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2a90e",
   "metadata": {},
   "source": [
    "## Train / Test Split\n",
    "\n",
    "To make Bayesian priors comparable across regressors, we need some transformation across regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97852c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using relatively updated data\n",
    "df = df[df[\"week\"] > \"2018-01-01\"].reset_index(drop=True)\n",
    "test_size = 12\n",
    "train_df = df[:-test_size].reset_index(drop=True)\n",
    "test_df = df[-test_size:].reset_index(drop=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_df[\n",
    "    [\"claims\", \"trend.unemploy\", \"trend.job\", \"sp500\", \"vix\"]\n",
    "] = scaler.fit_transform(\n",
    "    train_df[[\"claims\", \"trend.unemploy\", \"trend.job\", \"sp500\", \"vix\"]]\n",
    ")\n",
    "test_df[[\"claims\", \"trend.unemploy\", \"trend.job\", \"sp500\", \"vix\"]] = scaler.transform(\n",
    "    test_df[[\"claims\", \"trend.unemploy\", \"trend.job\", \"sp500\", \"vix\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff1a86",
   "metadata": {},
   "source": [
    "# Simple DLT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dlt = DLTFull(\n",
    "    response_col=response_col,\n",
    "    date_col=date_col,\n",
    "    seasonality=52,\n",
    "    seed=8888,\n",
    "    num_warmup=400,\n",
    "    num_sample=100,\n",
    ")\n",
    "\n",
    "dlt.fit(df=train_df)\n",
    "predicted_df = dlt.predict(df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_predicted_data(training_actual_df=train_df, predicted_df=predicted_df, \n",
    "                        date_col=date_col, actual_col=response_col, test_actual_df=test_df,\n",
    "                        title='DLT with Linear Global Trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f5493",
   "metadata": {},
   "source": [
    "# DLT With Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6951a5",
   "metadata": {},
   "source": [
    "The regressor columns can be supplied via argument `regressor_col`.  Recall the regression formula in **DLT**:\n",
    "\n",
    "$$\n",
    "\\hat{y}_t =\\mu_t + s_t + r_t \\\\\n",
    "r_t = \\sum_{j}\\beta_j x_{jt} \\\\\n",
    "\\beta_j ~\\sim \\mathcal{N}(\\mu_j, \\sigma_j^2)\n",
    "$$\n",
    "\n",
    "Let's use the default where $\\mu_j = 0$ and $\\sigma_j = 1$.  In addition, we can set a *sign* constraint for each coefficient $\\beta_j$.  This is can be done by supplying the `regressor_sign` as a list where elements are in one of followings:\n",
    "\n",
    "* '=': $\\beta_j ~\\sim \\mathcal{N}(0, \\sigma_j^2)$  i.e. $\\beta_j \\in (-\\inf, \\inf)$\n",
    "* '+': $\\beta_j ~\\sim \\mathcal{N}^+(0, \\sigma_j^2)$  i.e. $\\beta_j \\in [0, \\inf)$\n",
    "* '-': $\\beta_j ~\\sim \\mathcal{N}^-(0, \\sigma_j^2)$  i.e. $\\beta_j \\in (-\\inf, 0]$\n",
    "\n",
    "Based on some intuition, it's reasonable to assume search terms such as \"unemployment\", \"filling\" and **VIX** index to be positively correlated and stock index such as **SP500** to be negatively correlated to the outcome.  Then we will leave whatever unsured as a regular regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48537ac",
   "metadata": {},
   "source": [
    "## Regular Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt_reg = DLTFull(\n",
    "    response_col=response_col, \n",
    "    date_col=date_col,\n",
    "    regressor_col=['trend.unemploy', 'trend.job', 'sp500', 'vix'],\n",
    "    seasonality=52,\n",
    "    num_warmup=4000,\n",
    "    num_sample=1000,\n",
    ")\n",
    "\n",
    "dlt_reg.fit(df=train_df)\n",
    "predicted_df_reg = dlt_reg.predict(test_df, decompose=True)\n",
    "\n",
    "_ = plot_predicted_data(training_actual_df=train_df, predicted_df=predicted_df_reg, \n",
    "                        date_col=date_col, actual_col=response_col, test_actual_df=test_df,\n",
    "                        title='DLT with Regular Regresion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e090f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_predicted_data(training_actual_df=train_df, predicted_df=predicted_df_reg, \n",
    "                        date_col=date_col, actual_col=response_col, test_actual_df=test_df,\n",
    "                        title='DLT with Regular Regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bebebb",
   "metadata": {},
   "source": [
    "The estimated regressor coefficients can be retrieved via `.get_regression_coefs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt_reg.get_regression_coefs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e5068",
   "metadata": {},
   "source": [
    "### Diagnoses\n",
    "#### Decomposition \n",
    "\n",
    "`plot_predicted_components` is the utility to plot each component separately. This is useful when one wants to look into the model prediction results and inspect each component separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f669d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_predicted_components(predicted_df_reg, date_col, \n",
    "                              plot_components=['prediction', 'trend', 'seasonality', 'regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d11c0",
   "metadata": {},
   "source": [
    "#### Posterior Diagnostic Visualizations\n",
    "\n",
    "`plot_posterior_params` is the main utility for different kinds of diagnostic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a32edc",
   "metadata": {},
   "source": [
    "##### Trace plot\n",
    "\n",
    "Trace plot shows the iterations of each paramter over the Markov chian sampling process. Trace plots provide an important tool for assessing mixing of a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26265a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_posterior_params(dlt_reg, kind='trace',\n",
    "                          incl_trend_params=False, incl_smooth_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82980ff5",
   "metadata": {},
   "source": [
    "##### Density/Histogram\n",
    "\n",
    "By setting `kind = 'density'`, we get posterior paramter density plot. It shows the mean, median and confidence Interval (95% by default) of various paramter posterior samples. One can specify a path string (e.g., './density.png') to save the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea017a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_posterior_params(dlt_reg, kind='density',\n",
    "                          incl_trend_params=False, incl_smooth_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606b82e",
   "metadata": {},
   "source": [
    "##### Pair Plot\n",
    "\n",
    "By setting `kind = 'pair'`, it will generates a series of pair plots, which depict the relationship between every two parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_posterior_params(dlt_reg, kind='pair', pair_type='reg', \n",
    "                          incl_trend_params=False, incl_smooth_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a84415",
   "metadata": {},
   "source": [
    "## Regression with Informative Priors / Regularized Priors\n",
    "\n",
    "Assuming users obtain further knowledge on some of the regressors, they could use informative priors ($\\mu$, $\\sigma$) by replacing the defaults. This can be done via the arguments `regressor_beta_prior` and `regressor_sigma_prior`. These two lists should be of the same lenght as `regressor_col`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa501319",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt_reg_adjust = DLTFull(\n",
    "    response_col=response_col,\n",
    "    date_col=date_col,\n",
    "    regressor_col=['trend.unemploy', 'trend.job', 'sp500','vix'],\n",
    "    # regressor_sign=['+','=','-','+'],\n",
    "    # regressor_beta_prior=['0.3, 0.01, -0.09, -0.016],\n",
    "    regressor_sigma_prior=[0.1] * 4,\n",
    "    seasonality=52,\n",
    "    seed=8888,\n",
    "    num_warmup=4000,\n",
    "    num_sample=1000,\n",
    ")\n",
    "dlt_reg_adjust.fit(df=train_df)\n",
    "predicted_df_reg_adjust = dlt_reg_adjust.predict(test_df, decompose=True)\n",
    "\n",
    "_ = plot_predicted_data(training_actual_df=train_df, predicted_df=predicted_df_reg_adjust, \n",
    "                        date_col=date_col, actual_col=response_col, test_actual_df=test_df,\n",
    "                        title='DLT with Regresion of Informative Priors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_predicted_data(training_actual_df=train_df, predicted_df=predicted_df_reg_adjust, \n",
    "                        date_col=date_col, actual_col=response_col, test_actual_df=test_df,\n",
    "                        title='DLT with Regresion of Informative Priors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32013af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt_reg_adjust.get_regression_coefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_mae = mae(predicted_df['prediction'].values, test_df['claims'].values)\n",
    "reg_mae = mae(predicted_df_reg['prediction'].values, test_df['claims'].values)\n",
    "reg_adjust_mae = mae(predicted_df_reg_adjust['prediction'].values, test_df['claims'].values)\n",
    "\n",
    "print('Naive Model: {:.3f}\\nRegression Model: {:.3f}\\nRefined Regression Model: {:.3f}'.format(\n",
    "    naive_mae, reg_mae, reg_adjust_mae\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb214c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
